Number of states: 6
Discount factor: 0.8
Reward function and Available actions: 
S1 -> S2 = 0
S1 -> S4 = 0
S2 -> S1 = 0
S2 -> S3 = 50
S2 -> S5 = 0
S3 -> S3 = 0
S4 -> S1 = 0
S4 -> S5 = 0
S5 -> S2 = 0
S5 -> S4 = 0
S5 -> S6 = 0
S6 -> S3 = 100
S6 -> S5 = 0

Iterations to converge: 5

Optimal values:
V*[1] = 51.2
V*[2] = 64
V*[3] = 0
V*[4] = 64
V*[5] = 80
V*[6] = 100

Optimal policies:
PI[1] = 2
PI[2] = 5
PI[3] = 3
PI[4] = 5
PI[5] = 6
PI[6] = 3

Optimal policy for 1 to 3: 1 2 5 6 3
